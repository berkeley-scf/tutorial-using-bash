[
  {
    "objectID": "managing-processes.html",
    "href": "managing-processes.html",
    "title": "Managing processes",
    "section": "",
    "text": "A process is a program that is being executed. Processes have the following attributes:\nAnytime you do something on the computer, one or more processes will start up to carry out the activity.",
    "crumbs": [
      "Managing Processes"
    ]
  },
  {
    "objectID": "managing-processes.html#monitoring",
    "href": "managing-processes.html#monitoring",
    "title": "Managing processes",
    "section": "1 Monitoring",
    "text": "1 Monitoring\n\n1.1 Monitoring processes\n\nUsing ps\nExamining subprocesses of your shell with ps:\n$ ps\nPID   TTY          TIME CMD\n19370 pts/3    00:00:00 bash\n22846 pts/3    00:00:00 ps\nExamining in more detail subprocesses of your shell with ps:\n$ ps -f\nUID        PID  PPID  C STIME TTY          TIME CMD\njarrod   19370 19368  0 10:51 pts/3    00:00:00 bash\njarrod   22850 19370  0 14:57 pts/3    00:00:00 ps -f\nExamining in more detail all processes on your computer:\n$ ps -ef\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 Aug21 ?        00:00:05 /usr/lib/systemd\nroot         2     0  0 Aug21 ?        00:00:00 [kthreadd]\nroot         3     2  0 Aug21 ?        00:00:07 [ksoftirqd/0]\nroot         5     2  0 Aug21 ?        00:00:00 [kworker/0:0H]\n&lt;snip&gt;\nroot     16210     1  0 07:19 ?        00:00:00 login -- jarrod\njarrod   16219 16210  0 07:19 tty1     00:00:00 -bash\njarrod   16361 16219  0 07:19 tty1     00:00:00 /bin/sh /bin/startx\n&lt;snip&gt;\nYou can use the -u option to see percent CPU and percent memory used by each process. You can use the -o option to provide your own user-defined format; for example, :\n$ ps -o pid,ni,pcpu,pmem,user,comm\nPID    NI %CPU %MEM USER     COMMAND\n18124   0  0.0  0.0 jarrod   bash\n22963   0  0.0  0.0 jarrod   ps\nTo see the hierarchical process structure (i.e., which processes started which other processes), you can use the pstree command.\n\n\nUsing top\nExamining processes with top:\n$ top\ntop - 13:49:07 up  1:49,  3 users,  load average: 0.10, 0.15, 0.18\nTasks: 160 total,   1 running, 158 sleeping,   1 stopped,   0 zombie\n%Cpu(s):  2.5 us, 0.5 sy, 0.0 ni, 96.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\nKiB Mem : 7893644 total, 5951552 free, 1085584 used,  856508 buff/cache\nKiB Swap: 7897084 total, 7897084 free,       0 used. 6561548 avail Mem\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n1607 jarrod   20   0 2333568 974888 212944 S  12.5 12.4  11:10.67 firefox\n3366 jarrod   20   0  159828   4312   3624 R   6.2  0.1   0:00.01 top\n   1 root     20   0  193892   8484   5636 S   0.0  0.1   0:01.78 systemd\n&lt;snip&gt;\nThe first few lines show general information about the machine, while the remaining lines show information for each process.\n\nThe RES column indicates the amount of memory that a process is using (in bytes, if not otherwise indicated).\nThe %MEM shows that memory use relative to the physical memory available on the computer.\nThe %CPU column shows the proportion of a CPU core that the process is using (which can exceed 100% if a process is threaded).\nThe TIME+ column shows the amount of time the process has been running.\n\nTo quit top, type q.\nYou can also kill jobs (see below for further details on killing jobs) from within top: just type r or k, respectively, and proceed from there.\n\n\n\n1.2 Monitoring memory use\nOne of the main things to watch out for is a job that is using close to 100% of memory and much less than 100% of CPU. What is generally happening is that your program has run out of memory and is using virtual memory on disk, spending most of its time writing to/from disk, sometimes called paging or swapping. If this happens, it can be a very long time, if ever, before your job finishes.\nNote that the per-process memory use reported by top and ps may “double count” memory that is being used simultaneously by multiple processes. To see the total amount of memory actually available on a machine:\n$ free -h\n              total        used        free      shared  buff/cache   available\nMem:           251G        998M        221G        2.6G         29G        247G\nSwap:          7.6G        210M        7.4G\nYou’ll generally be interested in the Memory row and in the total, used and available columns. The free column can be confusing and does not actually indicate how much memory is still available to be used, so you’ll want to focus on the available column.",
    "crumbs": [
      "Managing Processes"
    ]
  },
  {
    "objectID": "managing-processes.html#job-control",
    "href": "managing-processes.html#job-control",
    "title": "Managing processes",
    "section": "2 Job Control",
    "text": "2 Job Control\n\n2.1 Foreground and background jobs\nWhen you run a command in a shell by simply typing its name, you are said to be running in the foreground. When a job is running in the foreground, you can’t type additional commands into that shell session, but there are two signals that can be sent to the running job through the keyboard. To interrupt a program running in the foreground, use Ctrl-c; to quit a program, use Ctrl-\\. While modern windowed systems have lessened the inconvenience of tying up a shell with foreground processes, there are some situations where running in the foreground is not adequate.\nThe primary need for an alternative to foreground processing arises when you wish to have jobs continue to run after you log off the computer. In cases like this you can run a program in the background by simply terminating the command with an ampersand (&). However, before putting a job in the background, you should consider how you will access its results, since stdout is not preserved when you log off from the computer. Thus, redirection (including redirection of stderr) is essential when running jobs in the background. As a simple example, suppose that you wish to run a Python script, and you don’t want it to terminate when you log off.\n$ python code.py &gt; code.pyout 2&gt;&1 &\nWhat does the inscrutable 2&gt;&1 do? Recall from earlier that it says to send stderr to the same place as stdout, which in this case has been redirected to code.pyout.\nIf you forget to put a job in the background when you first execute it, you can do it while it’s running in the foreground in two steps. First, suspend the job using the Ctrl-z signal. After receiving the signal, the program will interrupt execution, but it will still have access to all files and other resources. Next, issue the bg command, which will start the stopped job running in the background.\n\n\n2.2 Listing and killing jobs\nSince only foreground jobs will accept signals through the keyboard, if you want to terminate a background job you must first determine the unique process id (PID) for the process you wish to terminate through either ps or top. Here we’ll illustrate use of ps again.\nTo see all processes owned by a specific user (e.g., jarrod), I can use the -U jarrod option:\n$ ps -U jarrod\nIf I want to get more information (e.g., %CPU and %MEM), I can use add the -u option:\n$ ps -U jarrod -u\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START    TIME COMMAND\njarrod   16116 12.0  6.0 118804  5080 tty1     Ss   16:25  133:01 python\nIn this example, the ps output tells us that this python job has a PID of 16116, that it has been running for 133 minutes, is using 12% of CPU and 6% of memory, and that it started at 16:25. You could then issue the command:\n$ kill 16116\nor, if that doesn’t work:\n$ kill -9 16116\nto terminate the job. Another useful command in this regard is killall, which accepts a program name instead of a process id, and will kill all instances of the named program (in this case, R):\n$ killall R\nOf course, it will only kill the jobs that belong to you, so it will not affect the jobs of other users. Note that the ps and kill commands only apply to the particular computer on which they are executed, not to the entire computer network. Thus, if you start a job on one machine, you must log back into that same machine in order to manage your job.\nFinally, let’s see how to build up a command to kill firefox using some of the tools we’ve seen. First let’s pipe the output of ps -e to grep to select the line corresponding to firefox:\n$ ps -e | grep firefox\n16517 ?        00:10:03 firefox\nWe can now use awk to select the first column, which contains the process ID corresponding to firefox:\n$ ps -e | grep firefox | awk '{ print $1 }'\n16517\nFinally, we can pipe this to the kill command using xargs or command substitution:\n$ ps -e | grep firefox | awk '{ print $1 }' | xargs kill\n$ kill $(ps -e | grep firefox | awk '{ print $1 }')\nAs mentioned before, we can’t pipe the PID directly to kill because kill takes the PID(s) as argument(s) rather than reading them from stdin.",
    "crumbs": [
      "Managing Processes"
    ]
  },
  {
    "objectID": "managing-processes.html#screen",
    "href": "managing-processes.html#screen",
    "title": "Managing processes",
    "section": "3 Screen",
    "text": "3 Screen\nScreen allows you to create virtual terminals, which are not connected to your actual terminal or shell. This allows you to run multiple programs from the command line and leave them all in the foreground in their own virtual terminal. Screen provides facilities for managing several virtual terminals including:\n\nlisting them,\nswitching between them, and\ndisconnecting from one machine and then reconnecting to an existing virtual terminal from another.\n\nWhile we will only discuss its basic operation, we will cover enough to be of regular use.\ntmux is an alternative to screen.\nCalling screen:\n$ screen\nwill open a single window and you will see a new bash prompt. You just work at this prompt as you normally would. The difference is that you can disconnect from this window by typing Ctrl-a d and you will see something like this :\n$ screen\n[detached from 23974.pts-2.t430u]\n\n\n\n\n\n\nScreen commands\n\n\n\nAll the screen key commands begin with the control key combination Ctrl-a followed by another key. For instance, when you are in a screen session and type Ctrl-a ?, screen will display a help screen with a list of its keybindings.\n\n\nYou can now list your screen sessions :\n$ screen -ls\nThere is a screen on:\n    23974.pts-2.t430u       (Detached)\nTo reconnect :\n$ screen -r\nYou can start multiple screen sessions. This is what it might look like if you have 3 screen sessions:\n$ screen -ls\nThere are screens on:\n    24274.pts-2.t430u       (Attached)\n    24216.pts-2.t430u       (Detached)\n    24158.pts-2.t430u       (Detached)\nwith the first session active on a machine.\nTo specify that you want to reattach to session 24158.pts-2.t430u, type:\n$ screen -r 24158.pts-2.t430u\nIf you have several screen sessions, you will want to name your screen session something more informative than 24158.pts-2.t430u. To name a screen session gene-analysis you can use the -S option when calling screen:\n$ screen -S gene-analysis\nWhile there are many more features and keybindings available for screen, you’ve already seen enough screen to be useful. For example, imagine you ssh to a remote machine from your laptop to run an analysis. The first thing you do at the bash prompt on the remote machine is:\n$ screen -S dbox-study\nThen you start your analysis script dbox-analysis.py running:\n$ dbox-analysis.py\nStarting statistical analysis ...\nProcessing subject 1 ...\nProcessing subject 2 ...\nIf your study has 50 subjects and processing each subject takes 20 minutes, you will not want to sit there watching your monitor. So you use Ctrl-a d to detach the session and you will then see:\n$ screen -S dbox-study\n[detached from 2799.dbox-study]\n$\nNow you can log off your laptop and go home. Sometime after dinner, you decide to check on your job. So you ssh from your home computer to the remote machine again and type the following at the bash prompt:\n$ screen -r dbox-study\nYou should then be able to see the progress of your analysis script, as if you had kept a terminal open the whole time.",
    "crumbs": [
      "Managing Processes"
    ]
  },
  {
    "objectID": "shell-programming.html",
    "href": "shell-programming.html",
    "title": "Shell programming",
    "section": "",
    "text": "Shell scripts are files containing shell commands (commonly with the extension .sh) To run a shell script called file.sh, you would type :\n$ source ./file.sh\nor :\n$ . ./file.sh\nNote that if you just typed file.sh, the operating system will generally have two problems: first, it would have trouble finding the script (if file.sh is not in a directory included in the PATH environment variable), and second it would have trouble recognizing that it is executable (if the -x flag is not set for file.sh).\nTo be sure that the operating system knows what shell to use to interpret the script, the first line of the script should be #!/bin/bash (in the case that you’re using the bash shell).\nThe best thing to do is to set file.sh to be executable (i.e., to have the ‘x’ flag set), and you can can execute it simply with:\n$ ./file.sh",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "shell-programming.html#shell-scripts",
    "href": "shell-programming.html#shell-scripts",
    "title": "Shell programming",
    "section": "",
    "text": "Shell scripts are files containing shell commands (commonly with the extension .sh) To run a shell script called file.sh, you would type :\n$ source ./file.sh\nor :\n$ . ./file.sh\nNote that if you just typed file.sh, the operating system will generally have two problems: first, it would have trouble finding the script (if file.sh is not in a directory included in the PATH environment variable), and second it would have trouble recognizing that it is executable (if the -x flag is not set for file.sh).\nTo be sure that the operating system knows what shell to use to interpret the script, the first line of the script should be #!/bin/bash (in the case that you’re using the bash shell).\nThe best thing to do is to set file.sh to be executable (i.e., to have the ‘x’ flag set), and you can can execute it simply with:\n$ ./file.sh",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "shell-programming.html#functions",
    "href": "shell-programming.html#functions",
    "title": "Shell programming",
    "section": "2 Functions",
    "text": "2 Functions\nYou can define your own utilities by creating a shell function. This allows you to automate things that are more complicated than you can do with an alias. One nice thing about shell functions is that the shell automatically takes care of function arguments for you. It places the arguments given by the user into local variables in the function called (in order): $1 $2 $3 etc. It also fills $# with the number of arguments given by the user. Here’s an example of using arguments in a function that saves me some typing when I want to copy a file to the SCF filesystem:\nfunction putscf() {\n   scp $1 jarrod@arwen.berkeley.edu:$2\n}\nTo use this function, I just do the following to copy unit1.pdf from the current directory on whatever non-SCF machine I’m on to the directory ~/teaching/243 on SCF:\n$ putscf unit1.pdf teaching/243/.\nOften you’d want to put such functions in your .bashrc file.",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "shell-programming.html#ifthenelse",
    "href": "shell-programming.html#ifthenelse",
    "title": "Shell programming",
    "section": "3 If/then/else",
    "text": "3 If/then/else\nWe can use if-then-else type syntax to control the flow of a shell script. For an example, here is a shell function niceR() that can be used for nicing R jobs:\n    # niceR shortcut for nicing R jobs \n    # usage: niceR inputRfile outputRfile \n    # Author: Brian Caffo \n    # Date: 10/01/03 \n\n    function niceR(){\n        # submits nice'd R jobs\n        if [ $# != \"2\" ]; then\n             echo \"usage: niceR inputRfile outputfile\" \n        elif [ -e \"$2\" ]; then\n             echo \"$2 exists, I won't overwrite\" \n        elif [ ! -e \"$1\" ]; then\n             echo \"inputRfile $1 does not exist\" \n        else\n             echo \"running R on $1\" \n             nice -n 19 R --no-save &lt; $1 &&gt; $2\n        fi\n    }\nIf the then is on a separate line from the if, you won’t need the semicolon.",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "shell-programming.html#for-loops",
    "href": "shell-programming.html#for-loops",
    "title": "Shell programming",
    "section": "4 For loops",
    "text": "4 For loops\nFor loops in shell scripting are primarily designed for iterating through a set of files or directories. Here’s an example:\n$ for FILE in $(ls *.txt); do\n&gt;    mv $file ${FILE/.txt/.R}\n&gt;   # this syntax replaces .txt with .R in $FILE``\n&gt; done\nNote that the &gt; prompt above occurs when the shell is expecting further input.\nAnother use of for loops is automating file downloads:\n    # example of bash for loop and wget for downloading a collection of files on the web\n    # usage: ./forloopDownload.sh\n    # Author: Chris Paciorek\n    # Date: July 28, 2011\n\n    url='ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/grid/years'\n    types=\"tmin tmax\"\n    for ((yr=1950; yr&lt;=2017; yr++))\n    do\n        for type in ${types}\n        do\n            wget ${url}/${yr}.${type}\n        done\n    done\nIf the do is on a separate line from the for, you don’t need the semicolon seen in the previous example.\nfor loops are very useful for starting a series of jobs:\n    # example of bash for loop for starting jobs\n    # usage: ./forloopJobs.sh\n    # Author: Chris Paciorek\n    # Date: July 28, 2011\n\n    n=100 \n    for(( it=1; it&lt;=100; it++ ))\n    do\n        echo \"n=$n; it=$it; source('base.R')\" &gt; tmp-$n-$it.R   # create customized R file\n        R CMD BATCH --no-save tmp-$n-$it.R sim-n$n-it$it.Rout\n    done\n    # note that base.R should NOT set either 'n' or 'it'\nThat’s just an illustration. In reality, in the case above you’d be better off passing arguments into the R code using commandArgs or by setting environment variables that are read in the R code.\nNote by default the separator when you’re looping through elements of a variable will be a space (as above), but you can set it differently, for example:\n$ IFS=:\n$ types=tmin:tmax:pmin:pmax\n$ for type in $types\n&gt; do\n&gt;    echo $type\n&gt; done\ntmin\ntmax\npmin\npmax",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "shell-programming.html#how-much-shell-scripting-should-i-learn",
    "href": "shell-programming.html#how-much-shell-scripting-should-i-learn",
    "title": "Shell programming",
    "section": "5 How much shell scripting should I learn?",
    "text": "5 How much shell scripting should I learn?\nWe’ve covered most of what you are likely to need to know about the shell. I tend to only use bash scripts for simple tasks that require only a few lines of bash commands and limited control flow (i.e., conditional statements, loops). For more complicated OS tasks, it is often preferable to use Python. (You can also do a fair amount of what you need from within R using the system() function.) This will enable you to avoid dealing with a lot of shell programming syntax. But you’ll still need to know how to use standard UNIX commands/utilities, wildcards, and pipes to be effective.",
    "crumbs": [
      "Shell Programming"
    ]
  },
  {
    "objectID": "using-commands.html",
    "href": "using-commands.html",
    "title": "Using UNIX commands",
    "section": "",
    "text": "Earlier we introduced the basics of entering commands in the shell.\nSince files are such an essential aspect of Unix and working from the shell is the primary way to work with Unix, there are a large number of useful commands and tools to view and manipulate files.\n\ncat – concatenate files and print to standard output\ncp – copy files and directories\ncut –_remove sections from each line of files\ndiff – find differences between two files\ngrep – print lines matching a pattern\nhead – output the first part of files\nfind –  search for files in a directory hierarchy\nless – opposite of more (and better than more)\nmore – file perusal filter for crt viewing\nmv – move (rename) files\nnl – number lines of files\npaste – merge lines of files\nrm – remove files or directories\nrmdir – remove empty directories\nsort – sort lines of text files.\nsplit – split a file into pieces\ntac – concatenate and print files in reverse\ntail – output the last part of files\ntouch – change file timestamps\ntr – translate or delete characters\nuniq – remove duplicate lines from a sorted file\nwc – print the number of bytes, words, and lines in files\nwget and curl – non-interactive internet downloading\n\nRecall that a command consists of the command, optionally one or more flags, and optionally one or more arguments. When there is an argument, it is often the name of a file that the command should operate on.\nThus the general syntax for a Unix program/command/utility is:\n$ command -options argument1 argument2 ...\nFor example, :\n$ grep -i graphics file.txt\nlooks for the literal string graphics (argument 1) in file.txt (argument2) with the option -i, which says to ignore the case of the letters. A simpler invocation is:While :\n$ less file.txt\nwhich simply pages through a text file (you can navigate up and down with the space bar and the up/down arrows) so you can get a feel for what’s in it. To exit less type q.\nUnix programs often take flags (options) that are identified with a minus followed by a letter and then (possibly) followed by the specific option (adding a space before the specific option is fine). Options may also involve two dashes, e.g., R --no-save. A standard two dash option for many commands is --help. For example, try:\n$ tail --help\nHere are a couple of examples of flags when using the tail command (-n 10 and -f):\n$ wget https://raw.githubusercontent.com/berkeley-scf/tutorial-using-bash/master/cpds.csv\n$ tail -n 10 cpds.csv   # last 10 lines of cpds.csv\n$ tail -f cpds.csv      # shows end of file, continually refreshing\nThe first line downloads the data from GitHub. The two main tools for downloading network-accessible data from the commandline are wget and curl. I tend to use wget as my commandline downloading tool as it is more convenient, but on a Mac, only curl is generally available.\nA few more tidbits about grep (we will see more examples of grep in the section on regular expressions, but it is so useful that it is worth seeing many times):\n$ grep ^2001 cpds.csv   # returns lines that start with '2001'\n$ grep 0$ cpds.csv      # returns lines that end with '0'\n$ grep 19.0 cpds.csv    # returns lines with '19' separated from '0' by a single character\n$ grep 19.*0 cpds.csv   # now separated by any number of characters\n$ grep -o 19.0 cpds.csv # returns only the content matching the pattern, not entire lines\nNote that the first argument to grep is the pattern you are looking for. The syntax is different from that used for wildcards in file names. Also, you can use regular expressions in the pattern, but we defer details until later.\nIt is sometimes helpful to put the pattern inside double quotes, e.g., if you want spaces in your pattern:\n$ grep \"George .* Bush\" cpds.csv\nMore generally in Unix, enclosing a string in quotes is often useful to indicate that it is a single argument/value.\nIf you want to explicitly look for one of the special characters used in creating patterns (such as double quote (\"), period (.), etc.), you can “escape” them by preceding with a back-slash. For example to look for \"Canada\", including the quotes:\n$ grep \"\\\"Canada\\\"\" cpds.csv     # look for \"Canada\" (including quotes)\n$ grep \"19\\.0\" cpds.csv              # look for 19.0\nIf you have a big data file and need to subset it by line (e.g., with grep) or by field (e.g., with cut), then you can do it really fast from the Unix command line, rather than reading it with R, SAS, Python, etc.\nMuch of the power of these utilities comes in piping between them (see the next section) and using wildcards to operate on groups of files. The utilities can also be used in shell scripts to do more complicated things.\nWe’ll see further examples of how to use these utilities later.\n\n\n\n\n\n\nExercise\n\n\n\nYou’ve already seen some of the above commands. Use the --help syntax to view the abbreviated man pages for some commands you’re not familiar with and consider how you might use these commands.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#basic-utilities-commands",
    "href": "using-commands.html#basic-utilities-commands",
    "title": "Using UNIX commands",
    "section": "",
    "text": "Earlier we introduced the basics of entering commands in the shell.\nSince files are such an essential aspect of Unix and working from the shell is the primary way to work with Unix, there are a large number of useful commands and tools to view and manipulate files.\n\ncat – concatenate files and print to standard output\ncp – copy files and directories\ncut –_remove sections from each line of files\ndiff – find differences between two files\ngrep – print lines matching a pattern\nhead – output the first part of files\nfind –  search for files in a directory hierarchy\nless – opposite of more (and better than more)\nmore – file perusal filter for crt viewing\nmv – move (rename) files\nnl – number lines of files\npaste – merge lines of files\nrm – remove files or directories\nrmdir – remove empty directories\nsort – sort lines of text files.\nsplit – split a file into pieces\ntac – concatenate and print files in reverse\ntail – output the last part of files\ntouch – change file timestamps\ntr – translate or delete characters\nuniq – remove duplicate lines from a sorted file\nwc – print the number of bytes, words, and lines in files\nwget and curl – non-interactive internet downloading\n\nRecall that a command consists of the command, optionally one or more flags, and optionally one or more arguments. When there is an argument, it is often the name of a file that the command should operate on.\nThus the general syntax for a Unix program/command/utility is:\n$ command -options argument1 argument2 ...\nFor example, :\n$ grep -i graphics file.txt\nlooks for the literal string graphics (argument 1) in file.txt (argument2) with the option -i, which says to ignore the case of the letters. A simpler invocation is:While :\n$ less file.txt\nwhich simply pages through a text file (you can navigate up and down with the space bar and the up/down arrows) so you can get a feel for what’s in it. To exit less type q.\nUnix programs often take flags (options) that are identified with a minus followed by a letter and then (possibly) followed by the specific option (adding a space before the specific option is fine). Options may also involve two dashes, e.g., R --no-save. A standard two dash option for many commands is --help. For example, try:\n$ tail --help\nHere are a couple of examples of flags when using the tail command (-n 10 and -f):\n$ wget https://raw.githubusercontent.com/berkeley-scf/tutorial-using-bash/master/cpds.csv\n$ tail -n 10 cpds.csv   # last 10 lines of cpds.csv\n$ tail -f cpds.csv      # shows end of file, continually refreshing\nThe first line downloads the data from GitHub. The two main tools for downloading network-accessible data from the commandline are wget and curl. I tend to use wget as my commandline downloading tool as it is more convenient, but on a Mac, only curl is generally available.\nA few more tidbits about grep (we will see more examples of grep in the section on regular expressions, but it is so useful that it is worth seeing many times):\n$ grep ^2001 cpds.csv   # returns lines that start with '2001'\n$ grep 0$ cpds.csv      # returns lines that end with '0'\n$ grep 19.0 cpds.csv    # returns lines with '19' separated from '0' by a single character\n$ grep 19.*0 cpds.csv   # now separated by any number of characters\n$ grep -o 19.0 cpds.csv # returns only the content matching the pattern, not entire lines\nNote that the first argument to grep is the pattern you are looking for. The syntax is different from that used for wildcards in file names. Also, you can use regular expressions in the pattern, but we defer details until later.\nIt is sometimes helpful to put the pattern inside double quotes, e.g., if you want spaces in your pattern:\n$ grep \"George .* Bush\" cpds.csv\nMore generally in Unix, enclosing a string in quotes is often useful to indicate that it is a single argument/value.\nIf you want to explicitly look for one of the special characters used in creating patterns (such as double quote (\"), period (.), etc.), you can “escape” them by preceding with a back-slash. For example to look for \"Canada\", including the quotes:\n$ grep \"\\\"Canada\\\"\" cpds.csv     # look for \"Canada\" (including quotes)\n$ grep \"19\\.0\" cpds.csv              # look for 19.0\nIf you have a big data file and need to subset it by line (e.g., with grep) or by field (e.g., with cut), then you can do it really fast from the Unix command line, rather than reading it with R, SAS, Python, etc.\nMuch of the power of these utilities comes in piping between them (see the next section) and using wildcards to operate on groups of files. The utilities can also be used in shell scripts to do more complicated things.\nWe’ll see further examples of how to use these utilities later.\n\n\n\n\n\n\nExercise\n\n\n\nYou’ve already seen some of the above commands. Use the --help syntax to view the abbreviated man pages for some commands you’re not familiar with and consider how you might use these commands.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#streams-pipes-and-redirects",
    "href": "using-commands.html#streams-pipes-and-redirects",
    "title": "Using UNIX commands",
    "section": "3 Streams, pipes, and redirects",
    "text": "3 Streams, pipes, and redirects\n\n3.1 Streams (stdin/stdout/stderr)\nUnix programs that involve input and/or output often operate by reading input from a stream known as standard input (stdin), and writing their results to a stream known as standard output (stdout). In addition, a third stream known as standard error (stderr) receives error messages and other information that’s not part of the program’s results. In the usual interactive session, standard output and standard error default to your screen, and standard input defaults to your keyboard.\n\n\n3.2 Overview of redirection\nYou can change the place from which programs read and write through redirection. The shell provides this service, not the individual programs, so redirection will work for all programs. The following table shows some examples of redirection.\nTable. Common Redirection Operators\n\n\n\n\nRedirection Syntax\n\n\nFunction\n\n\n\n\n\n\n$ cmd &gt; file\n\n\nSend stdout to file\n\n\n\n\n$ cmd 1&gt; file\n\n\nSame as above\n\n\n\n\n$ cmd 2&gt; file\n\n\nSend stderr to file\n\n\n\n\n$ cmd &gt; file 2&gt;&1\n\n\nSend both stdout and stderr to file\n\n\n\n\n$ cmd &lt; file\n\n\nReceive stdin from file\n\n\n\n\n$ cmd &gt;&gt; file\n\n\nAppend stdout to file\n\n\n\n\n$ cmd 1&gt;&gt; file\n\n\nSame as above\n\n\n\n\n$ cmd 2&gt;&gt; file\n\n\nAppend stderr to file\n\n\n\n\n$ cmd &gt;&gt; file 2&gt;&1\n\n\nAppend both stdout and stderr to file\n\n\n\n\n$ cmd1 | cmd2\n\n\nPipe stdout from cmd1 to cmd2\n\n\n\n\n$ cmd1 2&gt;&1 | cmd2\n\n\nPipe stdout and stderr from cmd1 to cmd2\n\n\n\n\n$ cmd1 | tee file1 | cmd2\n\n\nPipe stdout from cmd1 to cmd2 while simultaneously writing it to file1\n\n\n\n\n\n\nusing tee\n\n\n\n\nNote that cmd may include options and arguments as seen in the previous section.\n\n\n3.3 Standard redirection (pipes)\nOperations where output from one command is used as input to another command (via the | operator) are known as pipes; they are made especially useful by the convention that many UNIX commands will accept their input through the standard input stream when no file name is provided to them.\nA simple pipe to wc to count the number of words in a string:\n$ echo \"hey there\" | wc -w\n2\nTranslating lowercase to UPPERCASE with tr:\n$ echo 'user1'  | tr 'a-z' 'A-Z'\nUSER1\nHere’s an example of finding out how many unique entries there are in the 2nd column of a data file whose fields are separated by commas:\n$ cut -d',' -f2 cpds.csv | sort | uniq | wc\n$ cut -d',' -f2 cpds.csv | sort | uniq &gt; countries.txt\nHere are the piecies of what is going on in the commands above:\n\nWe use the cut utility to extract the second field (-f2) or column of the file cpds.csv where the fields (or columns) are split or delimited by a comma (-d',').\nThe standard output of the cut command [is then piped (via |) to the standard input of the sort command.\nThen the output of sort is sent to the input of uniq to remove duplicate entries in the sorted list provided by sort. (Rather than using sort | uniq, you could also use sort -u.)\nFinally, the first of the cut commands prints a word count summary using wc; while the second saving the sorted information with duplicates removed in the file countries.txt.\n\nAs another example of checking for anomalies in a set of files, with the , to see if there are any “S” values in certain fields (based on fixed width using -b) of a set of files (USC*dly), one can do this:\n$ cut -b29,37,45,53,61,69,77,85,93,101,109,117,125,133,141,149, \\ \n            157,165,173,181,189,197,205,213,221,229,237,245,253, \\\n            261,269 USC*.dly | grep S | less\n(Note I did that on 22,000 files (5 Gb or so) in about 5 minutes on my desktop; it would have taken much more time to read the data into a program like R or Python.)\n\n\n3.4 The tee command\nThe tee command lets you create two streams from one. For example, consider the case where you want the results of this command:\n$ cut -d',' -f2 cpds.csv | sort | uniq \nto both be output to the terminal screen you are working in as well as being saved to a file. You could issue the command twice:\n$ cut -d',' -f2 cpds.csv | sort | uniq\n$ cut -d',' -f2 cpds.csv | sort | uniq &gt; countries.txt\nInstead of repeating the command and wasting computing time, you could use tee command:\n$ cut -d',' -f2 cpds.csv | sort | uniq | tee countries.txt",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#command-substitution-and-the-xargs-command",
    "href": "using-commands.html#command-substitution-and-the-xargs-command",
    "title": "Using UNIX commands",
    "section": "4 Command substitution and the xargs command",
    "text": "4 Command substitution and the xargs command\n\n4.1 Command substitution\nA closely related, but subtly different, capability to piping is command substitution. You may sometimes need to substitute the results of a command for use by another command. For example, if you wanted to use the directory listing returned by ls as the argument to another command, you would type $(ls) in the location you want the result of ls to appear.\nWhen the shell encounters a command surrounded by $(), it runs the command and replaces the expression with the output from the command. This allows something similar to a pipe, but it is appropriate when a command reads its arguments directly from the command line instead of through standard input.\nFor example, suppose we are interested in searching for the text pdf in the last 4 R code files (those with suffix .r or .R) that were modified in the current directory. We can find the names of the four most recently modified files ending in .R or .r using:\n$ ls -t *.{R,r} | head -4\nand we can search for the required pattern using grep . Putting these together with command substitution, we can solve the problem using:\n$ grep pdf $(ls -t *.{R,r} | head -4)\nSuppose that the four R code file names produced by the ls command above were: test.R, run.R, analysis.R , and process.R. Then the result of the command substitution above is to run the following command:\n$ grep pdf test.R run.R analysis.R process.R\n\n\n\n\n\n\nCommand substitution alternate syntax\n\n\n\nAn older notation for command substitution is to use backticks (e.g., `ls` rather than $(ls)). It is generally preferable to use the new notation, since there are many annoyances with the backtick notation. For example, backslashes (\\) inside of backticks behave in a non-intuitive way, nested quoting is more cumbersome inside backticks, nested substitution is more difficult inside of backticks, and it is easy to visually mistake backticks for a single quote.\n\n\nNote that piping the output of the ls command into grep would not achieve the desired goal, since grep reads its filenames as arguments from the command line, not standard input.\n\n\n4.2 The xargs command\nWhile it doesn’t work to directly use pipes to redirect output from one program as arguments to another program, you can redirect output as the arguments to another program using the xargs utility. Here’s an example:\n$ ls -t *.{R,r} | head -4 | xargs grep pdf\nwhere the result is equivalent to the use of command substitution we saw in the previous section.\n\n\n\n\n\n\nExercise\n\n\n\nTry the following commands:\n$ ls -l tr\n$ type -p tr\n$ ls -l type -p tr\n$ ls -l $(type -p tr)\nMake sure you understand why each command behaves as it does.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#brace-expansion",
    "href": "using-commands.html#brace-expansion",
    "title": "Using UNIX commands",
    "section": "5 Brace expansion",
    "text": "5 Brace expansion\nWe saw brace expansion when discussing file wildcards. For example, we can rename a file with a long name easily like this:\n$ mv my_long_filename.{txt,csv}\n$ ls my_long_filename*\nmy_long_filename.csv\n$ mv my_long_filename.csv{,-old}\n$ ls my_long_filename*\nmy_long_filename.csv-old\nThis works because the shell expands the braces before passing the result on to the command. So with the mv calls above, the shell expands the braces to produce\nmv my_long_filename.txt my_long_filename.csv\nmv my_long_filename.csv my_long_filename.csv-old\nBrace expansion is quite useful and more flexible than I’ve indicated. Above we saw how to use brace expansion using a comma-separated list of items inside the curly braces (e.g., {txt,csv}), but they can also be used with a sequence specification. A sequence is indicated with a start and end item separated by two periods (..). Try typing the following examples at the command line and try to figure out how they work:\n$ echo {1..15}\n$ echo c{c..e}\n$ echo {d..a}\n$ echo {1..5..2}\n$ echo {z..a..-2}\nThis can be used for filename wildcards but also anywhere else it would be useful. For example to kill a bunch of sequentially-numbered processes:\n$ kill 1397{62..81}",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#quoting",
    "href": "using-commands.html#quoting",
    "title": "Using UNIX commands",
    "section": "6 Quoting",
    "text": "6 Quoting\nA note about using single vs. double quotes in shell code. In general, variables inside double quotes will be evaluated, but variables not inside double quotes will not be:\n$ echo \"My home directory is $HOME\"\nMy home directory is /home/jarrod\n$ echo 'My home directory is $HOME'\nMy home directory is $HOME\nTable. Quotes\n\n\n\n\nTypes of Quoting\n\n\nDescription\n\n\n\n\n\n\n' '\n\n\nhard quote - no substitution allowed\n\n\n\n\n\" \"\n\n\nsoft quote - allow substitution\n\n\n\n\nThis can be useful, for example, when you have a directory with a space in its name (of course, it is better to avoid spaces in file and directory names). For example, suppose you have a directory named “with space” within the /home/jarrod home directory. Since bash uses spaces to parse the elements of the command line, you might try escaping any spaces with a backslash:\n$ ls $HOME/with\\ space\nfile1.txt\nHowever that can be a pain and may not work in all circumstances. A cleaner approach is to use soft (or double) quotes:\n$ ls \"$HOME/with space\"\nfile1.txt\nIf you used hard quotes, you will get this error:\n$ ls '$HOME/with space'\nls: cannot access $HOME/with space: No such file or directory\nWhat if you have double quotes in your file or directory name, such as a directory \"with\"quote (again, it is better to avoid using double quotes in file and directory names)? In this case, you will need to escape the quote:\n$ ls \"$HOME/\\\"with\\\"quote\"\nSo we’ll generally use double quotes. We can always work with a literal double quote by escaping it as seen above.\n\n\n\n\n\n\nCurly quotes\n\n\n\nAvoid using curly quotes (e.g., “ or ’) when coding (in the shell or otherwise), except as part of an actual string.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#powerful-tools-for-text-manipulation-grep-sed-and-awk",
    "href": "using-commands.html#powerful-tools-for-text-manipulation-grep-sed-and-awk",
    "title": "Using UNIX commands",
    "section": "7 Powerful tools for text manipulation: grep, sed, and awk",
    "text": "7 Powerful tools for text manipulation: grep, sed, and awk\nBefore the text editor, there was the line editor. Rather than presenting you with the entire text as a text editor does, a line editor only displays lines of text when it is requested to. The original Unix line editor is called ed. You will likely never use ed directly, but you will very likely use commands that are its descendants. For example, the commands grep, sed, awk, and vim are all based directly on ed (e.g., grep is a ed command that is now available as a standalone command, while sed is a streaming version of ed) or inherit much of its syntax (e.g., awk and vim both heavily borrow from the ed syntax). Since ed was written when computing resources were very constrained compared to today, this means that the syntax of these commands can be terse. However, it also means that learning the syntax for one of these tools will be rewarded when you need to learn the syntax of another of these tools.\nAn important benefit of these tools, particularly when working with large files, is that by operating line by line they don’t incur the memory use that would be involved in reading an entire file into memory in a program like Python or R and then operating on the file’s contents in memory.\nYou may not need to learn much sed or awk, but it is good to know about them since you can search the internet for awk or sed one-liners. If you have some file munging task, it can be helpful to do a quick search before writing code to perform the task yourself.\n\n7.1 grep\nThe simplest of these tools is grep. As I mentioned, ed only displays lines of text when requested. One common task was to print all the lines in a file matching a specific regular expression. The command in ed that does this is g/&lt;re&gt;/p, which stands for globally match all lines containing the regular express &lt;re&gt; and print them out.\nOne often uses grep with regular expressions, covered later, so we’ll just show some basic usage here.\nTo start you will need to create a file called testfile.txt with the following content:\nThis is the first line.\nFollowed by this line.\nAnd then ...\nTo print all the lines containing is:\n$ grep is testfile.txt\nThis is the first line.\nFollowed by this line.\nTo print all the lines not containing is:\n$ grep -v is testfile.txt \nAnd then ...\nTo print only the matches, one can use the -o flag, though this would generally only be interesting when used with a regular expression pattern since in this case, we know “is” is what will be returned:\n$ grep -o is testfile.txt\nis\nis\nis\nOne could also use --color so that the matches are highlighed in color.\n\n\n7.2 sed\nHere are some useful things you can do with sed. Note that as with other UNIX tools, sed will not generally directly alter a file (unless you use the -i flag); instead it will print the modified version of the file to stdout.\nPrinting lines of text with sed:\n$ sed -n '1,9p' file.txt       # prints out lines 1-9 from file.txt\n$ sed -n '/^#/p' file.txt      # prints out lines starting with # from file.txt \nThe first command prints out lines 1-9, while the second one prints out lines starting with #.\nDeleting lines of text with sed:\n$ sed -e '1,9d' file.txt\n$ sed -e '/^;/d' -e '/^$/d' file.txt\nThe first line deletes lines 1-9 of file.txt, printing the remaining lines to stdout. What do you think the second line does?\nNote that the -e flag is only necessary if you want to have more than one expression, so it’s not actually needed in the first line.\nText substitution with sed:\n$ sed 's/old_pattern/new_pattern/' file.txt &gt; new_file.txt\n$ sed 's/old_pattern/new_pattern/g' file.txt &gt; new_file.txt\n$ sed -i 's/old_pattern/new_pattern/g' file.txt \nThe first line replaces only the first instance in a line, while the second line replaces all instances in a line (i.e., globally). The use of the -i flag in the third line replaces the pattern in place in the file, thereby altering file.txt. Use the -i flag carefully as there is no way to easily restore the original version of the file.\n\n\n7.3 awk\nAwk is a general purpose programming language typically used in data extraction tasks and particularly well-suited to one-liners (although it is possible to write long programs in it, it is rare). For our purposes, we will just look at a few common one-liners to get a sense of how it works. Basically, awk will go through a file line by line and perform some action for each line.\nFor example, to select a given column from some text (here getting the PIDs of some processes, which are in the second ($2) column of the output of ps -f:\nps -f | awk '{ print $2 }'\nTo double space a file, you would read each line, print it, and then print a blank line:\n$ awk '{ print } { print \"\" }' file.txt \nPrint every line of a file that is longer than 80 characters:\n$ awk 'length($0) &gt; 80' file.txt\nPrint the home directory of every user defined in the file /etc/passwd:\n$ awk -F: '{ print $6 }' /etc/passwd\nTo see what that does, let’s look at the first line of /etc/passwd:\n$ head -n 1 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nAs you can see the entries are separated by colons (:) and the sixth field contains the root user’s home directory (/root). The option -F: specifies that the colon : is the field delimiter (instead of the default space delmiter) and print $6 prints the 6th field of each line.\nSumming columns:\n$ awk '{print $1 + $2}' file.txt\nThis will sum columns 1 and 2 of file.txt.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "using-commands.html#aliases-command-shortcuts-and-.bashrc",
    "href": "using-commands.html#aliases-command-shortcuts-and-.bashrc",
    "title": "Using UNIX commands",
    "section": "8 Aliases (command shortcuts) and .bashrc",
    "text": "8 Aliases (command shortcuts) and .bashrc\nAliases allow you to use an abbreviation for a command, to create new functionality or to insure that certain options are always used when you call an existing command. For example, I’m lazy and would rather type q instead of exit to terminate a shell window. You could create the alias as follow:\n$ alias q=exit\nAs another example, suppose you find the -F option of ls (which displays / after directories, \\ after executable files and @ after links) to be very useful. The command :\n$ alias ls=\"ls -F\"\nwill ensure that the -F option will be used whenever you use ls. If you need to use the unaliased version of something for which you’ve created an alias, precede the name with a backslash (\\). For example, to use the normal version of ls after you’ve created the alias described above:\n$ \\ls\nThe real power of aliases is only achieved when they are automatically set up whenever you log in to the computer or open a new shell window. To achieve that goal with aliases (or any other bash shell commands), simply insert the commands in the file .bashrc in your home directory. For example, here is an excerpt from my .bashrc:\n    # .bashrc\n\n    # Source global definitions\n    if [ -f /etc/bashrc ]; then\n            . /etc/bashrc\n    fi\n\n    # User specific aliases and functions\n    pushdp () {\n     pushd \"$(python -c \"import os.path as _, ${1}; \\\n       print _.dirname(_.realpath(${1}.__file__[:-1]))\"\n     )\"\n    }\n\n    export EDITOR=vim\n    source /usr/share/git-core/contrib/completion/git-prompt.sh\n    export PS1='[\\u@\\h \\W$(__git_ps1 \" (%s)\")]\\$ '\n\n    # history settings\n    export HISTCONTROL=ignoredups   # no duplicate entries\n    shopt -s histappend             # append, don't overwrite\n\n    # R settings\n    export R_LIBS=$HOME/usr/lib64/R/library\n    alias R=\"/usr/bin/R --quiet --no-save\"\n\n    # Set path\n    mybin=$HOME/usr/bin\n    export PATH=$mybin:$HOME/.local/bin:$HOME/usr/local/bin:$PATH:\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/usr/local/lib\n\n    # Additional aliases  \n    alias grep='grep --color=auto'\n    alias hgrep='history | grep'\n    alias l.='ls -d .* --color=auto'\n    alias ll='ls -l --color=auto'\n    alias ls='ls --color=auto'\n    alias more=less\n    alias vi=vim\n\n\n\n\n\n\nExercise\n\n\n\nLook over the content of the example .bashrc and make sure you understand what each line does. For instance, use man grep to see what the option --color=auto does. Use man which to figure out what the various options passed to it do.",
    "crumbs": [
      "Using Commands"
    ]
  },
  {
    "objectID": "file-management.html",
    "href": "file-management.html",
    "title": "File management",
    "section": "",
    "text": "In Unix, almost “everything is a file”. This means that a very wide variety of input and output resources (e.g., documents, directories, keyboards, hard drives, network devices) are streams of bytes available through the filesystem interface. This means that the basic file management tools are extremely powerful in Unix. Not only can you use these tools to work with files, but you can also use them to monitor and control many aspects of your computer.\nA file typically has these attributes:\n\nName\nType\nLocation\nSize\nProtection (i.e., permissions on what can be done with the file)\nTime, date, and user identification\n\nThese attributes are discussed further as part of our consideration of file permissions.\n\n\n\n\n\n\nPrerequisite\n\n\n\nIf you’re not familiar with moving between directories, listing files, or the structure of the filesystem, please see our Basics of UNIX tutorial.",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#overview",
    "href": "file-management.html#overview",
    "title": "File management",
    "section": "",
    "text": "In Unix, almost “everything is a file”. This means that a very wide variety of input and output resources (e.g., documents, directories, keyboards, hard drives, network devices) are streams of bytes available through the filesystem interface. This means that the basic file management tools are extremely powerful in Unix. Not only can you use these tools to work with files, but you can also use them to monitor and control many aspects of your computer.\nA file typically has these attributes:\n\nName\nType\nLocation\nSize\nProtection (i.e., permissions on what can be done with the file)\nTime, date, and user identification\n\nThese attributes are discussed further as part of our consideration of file permissions.\n\n\n\n\n\n\nPrerequisite\n\n\n\nIf you’re not familiar with moving between directories, listing files, or the structure of the filesystem, please see our Basics of UNIX tutorial.",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#finding-files-and-navigating-the-filesystem",
    "href": "file-management.html#finding-files-and-navigating-the-filesystem",
    "title": "File management",
    "section": "2 Finding files and navigating the filesystem",
    "text": "2 Finding files and navigating the filesystem\nYou can find files by name, modification time, and type:\n$ find . -name '*.txt'  # find files named *.txt\n$ find . -mtime -2      # find files modified less than 2 days ago\n$ find . -type l        # find links\nThe . argument here indicates to find the file(s) in the current working directory and any subdirectories.\nAs usual for UNIX commands, you can get more information about the find command with:\n$ man find\n$ find --help\nAs discussed in our Basics of UNIX tutorial, one uses cd to change directories. In addition to use of cd - to go back to the previous working directory, you can use the pushd, popd, and dirs commands if you would like to keep a stack of previous working directories rather than just the last one.\nIn each directory there are two special directories, . and .., which refer to the current directory and the parent of the current directory, respectively. One only sees these with ls if we use the -a flag to reveal hidden files.\n$ ls -al\ntotal 1489\ndrwxr-sr-x  7 paciorek scfstaff     31 Apr 21 16:39  ./\ndrwxr-sr-x 19 paciorek scfstaff     30 Feb 28 15:07  ../\nWe saw the use of . above with find.",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#filename-matching-globbing",
    "href": "file-management.html#filename-matching-globbing",
    "title": "File management",
    "section": "3 Filename matching (globbing)",
    "text": "3 Filename matching (globbing)\nShell file globbing will expand certain special characters (called wildcards) to match patterns of filenames, before passing those filenames on to a program. Note that the programs themselves don’t know anything about wildcards; it is the shell that does the expansion, so that programs don’t see the wildcards. The following table shows some of the special characters that the shell uses for expansion.\nTable. Filename wildcards\n\n\n\n\nWildcard\n\n\nFunction\n\n\n\n\n\n\n*\n\n\nMatch zero or more characters.\n\n\n\n\n?\n\n\nMatch exactly one character.\n\n\n\n\n[characters]\n\n\nMatch any single character from among characters listed between brackets.\n\n\n\n\n[!characters]\n\n\nMatch any single character other than characters listed between brackets.\n\n\n\n\n[a-z]\n\n\nMatch any single character from among the range of characters listed between brackets.\n\n\n\n\n[!a-z]\n\n\nMatch any single character from among the characters not in the range listed between brackets\n\n\n\n\n{frag1,frag2,…}\n\n\nBrace expansion: create strings frag1, frag2, etc.\n\n\n\n\nList all files ending with a digit:\n$ ls *[0-9]\nMake a copy of filename as filename.old:\n$ cp filename{,.old}\nRemove all files beginning with a or z:\n$ rm [az]*\nList all the R code files with a variety of suffixes:\n$ ls *.{r,R}\nThe echo command can be used to verify that a wildcard expansion will do what you think it will:\n$ echo cp filename{,.old}\ncp filename filename.old\nIf you want to suppress the special meaning of a wildcard in a shell command, precede it with a backslash (\\). (Note that this is a general rule of thumb in many similar situations when a character has a special meaning but you just want to treat it as a character.) For example to list files whose name starts with the * character:\n$ touch \\*test    # create a file called *test\n$ ls \\**\n*test\nTo read more about standard globbing patterns, see the man page:\n$ man 7 glob",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#file-permissions",
    "href": "file-management.html#file-permissions",
    "title": "File management",
    "section": "4 File permissions",
    "text": "4 File permissions\nUNIX allows you to control who has access to a given file (or directory) and how the user can interact with the file (or directory). We can see what permissions are set using the -l flag to ls.\n$ cd ~/stat243-fall-2020\n$ ls -l  \ntotal 152\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 data\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 howtos\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 project\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 ps\n-rw-rw-r--  1 scflocal scflocal 11825 Dec 28 13:15 README.md\ndrwxrwxr-x 13 scflocal scflocal  4096 Dec 28 13:15 sections\n-rw-rw-r--  1 scflocal scflocal 37923 Dec 28 13:15 syllabus.lyx\n-rw-rw-r--  1 scflocal scflocal 77105 Dec 28 13:15 syllabus.pdf\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:37 units\nWhen using the -l flag to ls, you’ll see extensive information about each file (or directory), of which the most important are:\n\n(column 1) file permissions (more later)\n(column 3) the owner of the file (‘scflocal’ here)\n(column 4) the group of users that the file belongs too (also ‘scflocal’ here)\n(column 5) the size of the file in bytes\n(column 6-8) the last time the file was modified\n(column 9) name of the file\n\nHere’s a graphical summary of the information for a file named “file.txt”, whose owner is “root” and group is “users”. (The graphic also indicates that the commands chmod, chown, and chgrp can be used to change aspects of the file permissions and ownership.)\n\n\n\nSchematic of file attributes\n\n\nLet’s look in detail at the information in the first column returned by ls -l.\n$ ls -l\ntotal 156\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 data\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 howtos\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 project\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:15 ps\n-rw-rw-r--  1 scflocal scflocal 11825 Dec 28 13:15 README.md\ndrwxrwxr-x 13 scflocal scflocal  4096 Dec 28 13:15 sections\n-rw-rw-r--  1 scflocal scflocal 37923 Dec 28 13:15 syllabus.lyx\n-rw-rw-r--  1 scflocal scflocal 77105 Dec 28 13:15 syllabus.pdf\ndrwxrwxr-x  2 scflocal scflocal  4096 Dec 28 13:37 units\nThe first column actually contains 10 individual single-character columns. Items marked with a d as the first character are directories. Here data is a directory while syllabus.pdf is not.\nFollowing that first character are three triplets of file permission information. Each triplet contains read (‘r’), write (‘w’) and execute (‘x’) information. The first rwx triplet (the second through fourth characters) indicates if the owner of the file can read, write, and execute a file (or directory). The second rwx triplet (the fifth through seventh characters) indicates if anyone in the group that the file belongs to can read, write and execute a file (or directory). The third triplet (the eighth through tenth characters) pertains to any other user. Dashes mean that a given user does not have that kind of access to the given file.\nFor example, for the syllabus.pdf file, the owner of the file can read it and can modify the file by writing to it (the first triplet is 'rw-'), as can users in the group the file belongs to. But for other users, they can only read it (the third triplet is 'r--').\nWe can change the permissions by indicating the type of user and the kind of access we want to add or remove. The type of user is one of:\n\n‘u’ for the user who owns the file,\n‘g’ for users in the group that the file belongs to, and\n‘o’ for any other users.\n\nThus we specify one of ‘u’, ‘g’, or ‘o’, followed by a ‘+’ to add permission or a ‘-’ to remove permission and finally by the kind of permission: ‘r’ for read access, ‘w’ for write access, and ‘x’ for execution access.\nAs a simple example, let’s prevent anyone from reading the tmp.txt file (which we’ll create first). We then try to print the contents of the file to the screen with the command cat, but we are denied.\nFirst recall the current permissions:\n$ echo \"first line\" &gt; tmp.txt  # create a test text file that contains \"first line\"\n$ ls -l tmp.txt\n-rw-rw-r--  1 scflocal scflocal    11 Dec 28 13:39 tmp.txt\nNow we remove the read permissions:\n$ chmod u-r tmp.txt # prevent owner from reading\n$ chmod g-r tmp.txt # prevent users in the file's group from reading\n$ chmod o-r tmp.txt # prevent others from reading\n$ ls -l tmp.txt\n--w--w---- 1 scflocal scflocal 11 Dec 28 13:39 tmp.txt\n$ cat tmp.txt\ncat: tmp.txt: Permission denied\nThat can actually be accomplished all at once, like this:\n$ chmod ugo-r tmp.txt # prevent all three\n$ ls -l tmp.txt\n--w--w---- 1 scflocal scflocal 11 Dec 28 13:39 tmp.txt\nOr if we wanted to remove read and write permission, we can do this:\n$ chmod ugo-rw tmp.txt # prevent all three\nNow if we try to add a line to the file, using the &gt;&gt; redirection operator, we are denied:\n$ echo \"added line\" &gt;&gt; tmp.txt  \n-bash: tmp.txt: Permission denied\nNow let’s restore read and write permission to the owner:\n$ chmod u+rw tmp.txt\n$ echo \"added line\" &gt;&gt; tmp.txt\n$ cat tmp.txt\nfirst line\nadded line\nThere’s lots more details that are important when making files accessible to other users, including:\n\nhow to make files in a particular directory available to other users on the system,\nhow to set up a directory for use by a UNIX group, using the so-called “sticky bit” so that files created in the directory in the future belong to the group so that group members will readily have access to them by default, and\nhow to use access control lists to have more control over access.",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#use-simple-text-files-when-possible",
    "href": "file-management.html#use-simple-text-files-when-possible",
    "title": "File management",
    "section": "5 Use simple text files when possible",
    "text": "5 Use simple text files when possible\nUNIX commands are designed as powerful tools to manipulate text files. This means that it’s helpful to store information in information in text files when possible (of course there are very good reasons to store large datasets in binary files as well, in particular speed of access to portions of the data and efficient storage formats).\nFurthermore, the basic UNIX commands that operate on files operate on a line by line basis (e.g., grep, sed, cut, etc.). So using formats where each line contains a distinct set of information (such as CSVs) is advantageous even compared to other text formats where related information is stored on multiple lines (such as XML and JSON).",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "file-management.html#document-formats-and-conversion",
    "href": "file-management.html#document-formats-and-conversion",
    "title": "File management",
    "section": "6 Document formats and conversion",
    "text": "6 Document formats and conversion\nThere are many plain text file formats (e.g., Markdown, reStructuredText, LaTeX). Pandoc is a widely used document converter. To convert a file written in markdown (report.md) to a PDF (report.pdf), you would do something like:\n$ pandoc -o report.pdf report.md\nFor a quick introduction to LaTeX, please see our Introduction to LaTeX tutorial and screencast.",
    "crumbs": [
      "File Management"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Using the bash (and zsh) shell",
    "section": "",
    "text": "Prerequisite\n\n\n\nBefore reading this, if you’re not already comfortable with basic commands for working with files (e.g. cd, ls, cp and the structure of the filesystem on a UNIX-like machine), you will want to be familiar with the introductory material in our Basics of UNIX tutorial.\n\n\n\n\nSoftware Carpentry has a very nice introductory lesson on the basics of the shell. It also has an accompanying YouTube video that covers some, but not all, of the topics of this tutorial.\nThe book Research Software Engineering with Python has several good in-depth chapters on the shell.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#this-tutorial",
    "href": "index.html#this-tutorial",
    "title": "Using the bash (and zsh) shell",
    "section": "",
    "text": "Prerequisite\n\n\n\nBefore reading this, if you’re not already comfortable with basic commands for working with files (e.g. cd, ls, cp and the structure of the filesystem on a UNIX-like machine), you will want to be familiar with the introductory material in our Basics of UNIX tutorial.\n\n\n\n\nSoftware Carpentry has a very nice introductory lesson on the basics of the shell. It also has an accompanying YouTube video that covers some, but not all, of the topics of this tutorial.\nThe book Research Software Engineering with Python has several good in-depth chapters on the shell.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#the-interactive-shell",
    "href": "index.html#the-interactive-shell",
    "title": "Using the bash (and zsh) shell",
    "section": "2 The interactive shell",
    "text": "2 The interactive shell\nThe shell is the UNIX program that provides an interactive computer programming environment. You use the shell when in a terminal window to interact with a UNIX-style operating system (e.g., Linux or MacOS). The shell sits between you and the operating system and provides useful commands and functionality. Basically, the shell is a program that serves to run other commands for you and show you the results.\nThe shell is a read-evaluate-print loop (REPL) environment. R and Python also provide REPL environments. A REPL reads a single expression or input, parses and evaluates it, prints the results, and then loops (i.e., returns control to you to continue your work).\n\n\n\n\n\n\nThe shell prompt\n\n\n\nI will use a $ prompt for bash. By convention, a regular user’s prompt in bash is $, while the root (or administrative) user’s prompt is #. However, it is common practice to never log on as the root user, even if you have root access. If you need to run a command with root privileges, you should use the sudo command.\n$ echo \"The current user is $USER.\"\nThe current user is paciorek.\n\n\nWhen you are working in a terminal window (i.e., a window with the command line interface), you’re interacting with a shell. There are actually different shells that you can use, of which bash is very common and is the default on many systems. In recent versions of MacOS, zsh is the default shell. There are others as well (e.g., sh, csh, tcsh, fish). I’ve generated this document based on using the bash shell on a computer running the Ubuntu Linux version 20.04 operating system, and this tutorial assumes you are using bash or zsh. That said, the basic ideas and the use of various commands are applicable to any UNIX shell, and you should be able to replicate most of the steps in this tutorial in other UNIX command line environments, with various substitutions of shell syntax specific to the shell you are using,\nThe shell is an amazingly powerful programming environment. From it you can interactively monitor and control almost any aspect of the OS and more importantly you can automate it. As you will see, bash has a very extensive set of capabilities intended to make both interactive as well as automated control simple, effective, and customizable.\n\n\n\n\n\n\nWarning\n\n\n\nIt can be difficult to distinguish what is shell-specific and what is just part of UNIX. Some of the material in this tutorial is not bash-specific but is general to UNIX.\nReference: Newham and Rosenblatt, Learning the bash Shell, 2nd ed.\n\n\n\n\n\n\n\n\nThe shell on a Mac\n\n\n\nUnfortunately, the behavior of shell commands on a Mac can be somewhat different than on Linux (e.g., on a Mac, one can’t do tail -n +5) because MacOS is based on BSD, which is not a Linux distribution. The behavior of the commands is distinct from the shell you are using.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#accessing-the-shell",
    "href": "index.html#accessing-the-shell",
    "title": "Using the bash (and zsh) shell",
    "section": "3 Accessing the shell",
    "text": "3 Accessing the shell\nThis tutorial assumes you already have access to a basic bash shell on a computer with network access (e.g., the Terminal on a Mac, the Ubuntu subsystem on Windows, or a terminal window on a Linux machine), as discussed in our Basics of UNIX tutorial.\nHere’s how you can see your default shell and change it if you like.\n\nWhat is my default shell?\n$ echo $SHELL\n/bin/bash\nTo change to bash on a one-time basis:\n$ bash\nTo make it your default:\n$ chsh /bin/bash\n\nIn the last example, /bin/bash should be whatever the path to the bash shell is, which you can figure out using:\n$ type bash\nbash is /usr/bin/bash",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#variables",
    "href": "index.html#variables",
    "title": "Using the bash (and zsh) shell",
    "section": "4 Variables",
    "text": "4 Variables\n\n4.1 Using variables\nJust like programming languages, you can use variables in the shell. Variables are names that have values assigned to them.\nTo access the value currently assigned to a variable, you can prepend the name with the dollar sign ($). To print the value you can use the echo command.\nFor example, I can find the username of the current user in the USER variable:\n$ echo $USER\npaciorek\nTo declare a variable, just assign a value to the name, without using $. For example, if you want to make a new variable with the name counter with the value 1:\n$ counter=1\nSince bash uses spaces to parse the expression you give it as input, it is important to note the lack of spaces around the equal sign. Try typing the command with and without spaces and note what happens.\nYou can also enclose the variable name in curly brackets, which comes in handy when you’re embedding a variable within a line of code, to make sure the shell knows where the variable name ends:\n$ base=/home/jarrod/\n$ echo ${base}src\n$ echo $basesrc\nMake sure you understand the difference in behavior in the last two lines.\n\n\n4.2 Environment variables\nThere are also special shell variables called environment variables that help to control the shell’s behavior. These are generally named in all caps. Type printenv to see them. You can create your own environment variable as follows:\n$ export base=/home/jarrod/\nThe export command ensures that other shells created by the current shell (for example, to run a program) will inherit the variable. Without the export command, any shell variables that are set will only be modified within the current shell. More generally, if you want a variable to always be accessible, you should include the definition of the variable with an export command in your .bashrc file.\nYou can control the appearance of the bash prompt using the PS1 variable:\n$ echo $PS1\nTo modify it so that it puts the username, hostname, and current working directory in the prompt:\n$ export PS1='[\\u@\\h \\W]\\$ '\n[user1@local1 ~]$",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#introduction-to-commands",
    "href": "index.html#introduction-to-commands",
    "title": "Using the bash (and zsh) shell",
    "section": "5 Introduction to commands",
    "text": "5 Introduction to commands\n\n5.1 Elements of a command\nWhile each command has its own syntax, there are some rules usually followed. Generally, a command line consists of 4 things: a command, command options, arguments, and line acceptance. Consider the following example:\n$ ls -l file.txt\nIn the above example, ls is the command, -l is a command option specifying to use the long format, file.txt is the argument, and the line acceptance is indicated by hitting the Enter key at the end of the line.\nAfter you type a command at the bash prompt and indicate line acceptance with the Enter key, bash parses the command and then attempts to execute the command. To determine what to do, bash first checks whether the command is a shell function (we will discuss functions below). If not, it checks to see whether it is a builtin. Finally, if the command is not a shell function nor a builtin, bash uses the PATH variable. The PATH variable is a list of directories:\n$ echo $PATH\n/home/jarrod/usr/bin:/usr/local/bin:/bin:/usr/bin:\nFor example, consider the following command:\n$ grep pdf file.txt\nWe will discuss grep later. For now, let’s ignore what grep actually does and focus on what bash would do when you press enter after typing the above command. First bash checks whether grep a shell function or a builtin. Once it determines that grep is neither a shell function nor a builtin, it will look for an executable file named grep first in /home/jarrod/usr/bin, then in /usr/local/bin, and so on until it finds a match or runs out of places to look. You can use type to find out where bash would find it:\n$ type grep\ngrep is hashed (/usr/bin/grep)\nAlso note that the shell substitutes in the values of variables and does other manipulations before calling the command. For example in the following example,\n$ myfile=file.txt\n$ grep pdf $myfile\nthe value of $myfile is substituted in before grep is called, so the command that is executed is grep pdf myfile.txt.\n\n\n5.2 Getting help with commands\nMost bash commands have electronic manual pages, which are accessible directly from the commandline. You will be more efficient and effective if you become accustomed to using these man pages. To view the man page for the command sudo, for instance, you would type:\n$ man ls\nAlternatively, for many commands you can use the --help flag:\n$ ls --help\n\n\n\n\n\n\nExercise\n\n\n\nConsider the following examples using the ls command:\n$ ls --all -l\n$ ls -a -l\n$ ls -al\nUse man ls to see what the command options do. Is there any difference in what the three versions of the command invocation above return as the result? What happens if you add a filename to the end of the command?",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#operating-efficiently-at-the-command-line",
    "href": "index.html#operating-efficiently-at-the-command-line",
    "title": "Using the bash (and zsh) shell",
    "section": "6 Operating efficiently at the command line",
    "text": "6 Operating efficiently at the command line\n\n6.1 Tab completion\nWhen working in the shell, it is often unnecessary to type out an entire command or file name, because of a feature known as tab completion. When you are entering a command or filename in the shell, you can, at any time, hit the tab key, and the shell will try to figure out how to complete the name of the command or filename you are typing. If there is only one such command found in the search path and you’re using tab completion with the first token of a line, then the shell will display its value and the cursor will be one space past the completed name. If there are multiple commands that match the partial name, the shell will display as much as it can. In this case, hitting tab twice will display a list of choices, and redisplay the partial command line for further editing. Similar behavior with regard to filenames occurs when tab completion is used on anything other than the first token of a command.\n\n\n\n\n\n\nTab completion in Python and R\n\n\n\nR and Python also provide tab completions for objects (including functions) and (in some cases) filenames.\n\n\n\n\n6.2 Keyboard shortcuts\nNote that you can use emacs-like control sequences (Ctrl-a, Ctrl-e, Ctrl-k) to navigate and delete characters.\nTable. Keyboard Shortcuts\n\n\n\n\nKey Strokes\n\n\nDescriptions\n\n\n\n\n\n\nCtrl-a\n\n\nBeginning of line\n\n\n\n\nCtrl-e\n\n\nEnd of line\n\n\n\n\nCtrl-k\n\n\nDelete line from cursor forward\n\n\n\n\nCtrl-w\n\n\nDelete word before cursor\n\n\n\n\nCtrl-y\n\n\npastes in whatever was deleted previously with Ctrl-k or Ctrl-w\n\n\n\n\nESC-F\n\n\nForward one word\n\n\n\n\nESC-B\n\n\nBackwards one word\n\n\n\n\nCtrl-d\n\n\nEOF; exit\n\n\n\n\nCtrl-c\n\n\nInterrupt current command\n\n\n\n\nCtrl-z\n\n\nSuspend current command\n\n\n\n\nCtrl-l\n\n\nClear screen\n\n\n\n\nCtrl-r\n\n\nEnables an interactive search history\n\n\n\n\n\n\n6.3 Command History and Editing\nBy using the up and down arrows, you can scroll through commands that you have entered previously. So if you want to rerun the same command, or fix a typo in a command you entered, just scroll up to it and hit enter to run it or edit the line and then hit enter.\nTo list the history of the commands you entered, use the history command:\n$ history\n      1    echo $PS1\n      2    PS1=$\n      3    bash\n      4    export PS1=$\n      5    bash\n      6    echo $PATH\n      7    which echo\n      8    ls --all -l\n      9    ls -a -l\n      10   ls -al\n      11   ls -al manual.xml\nThe behavior of the history command is controlled by a shell variables:\n$ echo $HISTFILE\n$ echo $HISTSIZE\nYou can also rerun previous commands as follows:\n$ !-n \n$ !gi\nThe first example runs the nth previous command and the second one runs the last command that started with ‘gi’.\nTable. Command History Expansion\n\n\n\n\nDesignator\n\n\nDescription\n\n\n\n\n\n\n!!\n\n\nLast command\n\n\n\n\n!n\n\n\nCommand numbered n in the history\n\n\n\n\n!-n\n\n\nCommand n previous\n\n\n\n\n!string\n\n\nLast command starting with string\n\n\n\n\n!?string\n\n\nLast command containing string\n\n\n\n\nstring1string2\n\n\nExecute the previous command with string2 substituted for string1\n\n\n\n\nIf you’re not sure what command you’re going to recall, you can append :p at the end of the text you type to do the recall, and the result will be printed, but not executed. For example:\n$ !gi:p\nYou can then use the up arrow key to bring back that statement for editing or execution.\nYou can also search for commands by doing Ctrl-r and typing a string of characters to search for in the search history. You can hit return to submit, Ctrl-c to get out, or ESC to put the result on the regular command line for editing.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#accessing-remote-machines",
    "href": "index.html#accessing-remote-machines",
    "title": "Using the bash (and zsh) shell",
    "section": "7 Accessing remote machines",
    "text": "7 Accessing remote machines\nYou likely already have ssh installed. SSH provides an encrypted mechanism to connect to a remote Unix-based (i.e., Linux or Mac) terminal. You can learn more about using ssh on various operating systems.\nTo ssh to another machine, you need to know its (host)name. For example, to ssh to arwen.berkeley.edu, one of the SCF machines, you would:\n$ ssh arwen.berkeley.edu\nPassword:\nAt this point you have to type your password. Alternatively, you can set up ssh so that you can use it without typing your password.\nIf you have a different username on the remote machine than on the machine you are on, you will need to specify it as well. For example, to specify the username jarrod, you would:\n$ ssh jarrod@arwen.berkeley.edu\nIf you want to view graphical applications on your local computer that are running on the remote computer you need to use the -X option:\n$ ssh -X jarrod@arwen.berkeley.edu\nAlternatively, if you want to copy a file (file1.txt) from your local computer to arwen.berkeley.edu, you can use the scp command, which securely copies files between machines:\n$ scp file1.txt jarrod@arwen.berkeley.edu:.\nThe above command will copy file1.txt from my current working directory on my local machine to jarrod’s home directory on arwen.berkeley.edu. The . following the : indicates that I want to copy the file to jarrod’s home directory on the remote machine, keeping the file name as it is. I could also replace . with any relative path from jarrod’s home directory on the remote machine or I could use an absolute path.\nTo copy a file (file2.txt) from arwen.berkeley.edu to my local machine:\n$ scp jarrod@arwen.berkeley.edu:file2.txt .\nI can even copy a file (file3.txt) owned by one user (jarrod) on one remote machine arwen.berkeley.edu to the account of another user (jmillman) on another remote machine scf-ug02.berkeley.edu:\n$ scp jarrod@arwen.berkeley.edu:file3.txt jmillman@arwen.berkeley.edu:.\nIf instead of copying a single file, I wanted to copy an entire directory (src) from one machine to another, I would use the -r option:\n$ scp -r src jmillman@arwen.berkeley.edu:.\nRegardless of whether you are working on a local computer or a remote one, it is occasionally useful to operate as a different user. For instance, you may need root (or administrative) access to change file permissions or install software. (Note this will only be possible on machines that you own or have special privileges on. The Ubuntu Subsystem on Windows is one way to have a virtual Linux machine for which you have root access.)\nFor example on an Ubuntu Linux machine (including the Ubuntu Subsystem on Windows), here’s how you can act as the ‘root’ user to update or add software on machines where you have administrative access:\nTo upgrade all the software on the machine:\n$ sudo apt-get upgrade\nTo install the text editor vim on the machine:\n$ sudo apt-get install vim",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Make a variable, called mypython that contains the path to Python on your machine. You shouldn’t need to manually type the path.\nConstruct a variable that has the value &lt;username&gt;@&lt;machinename&gt; using existing environment variables and the hostname utility.\nFigure out how to use the mkdir command to create the following directory structure in one short command:\ntemp\n├── proj1\n│   ├── code\n│   └── data\n├── proj2\n│   ├── code\n│   └── data\n└── proj3\n    ├── code\n    └── data\nHow would you count the number of lines in an input file, say a data file.\nPrint the first three lines of a file to the screen. Now print just the third line to the screen.\nPut the third line of a file in a new file.\nNow add the fifth line of the file to that same file from the previous problem.\nExtract the Australia data from the cpds.csv dataset and put it in a file called cpds_australia.csv. It’s OK if you do this in a straightforward way and it might fail if ‘Australia’ is present in an unexpected column.\nFind all the lines in a file that do not contain a comma. (You might use this to look for anomalies in a CSV file.)\nWrite shell code that creates files file1.txt, file2.txt, file3.txt, etc., with the word ‘blah’ as the only line in each file.\nWrite shell code that modifies each file from the previous problem so that the number 1, 2, 3, etc. is prepended to the appropriate file (i.e., there is a new first line in each file that simply contains the number corresponding to the file name).\nYou may want to write the code to do this operation on a single file before embedding the code in the loop.\nCreate a shell function that will run a Python job in the background such that I can run the job by typing:\n$ bpy file.py file.out\nYou can create a test jobs with: echo -e 'a=5\\nprint(a)' &gt; file.py\nModify the function so that you can simply type :\n$ bpy file.py\nand it will use file.pyout as the output file.\nUse ps to print out all the processes on the machine with information on memory and CPU use and sort the output of ps in decreasing order of memory use.\nTake $mypython from the first problem and strip the python off the end—assigning the result to a new variable, path_to_py.",
    "crumbs": [
      "Exercises"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work (by Christopher Paciorek and Jarrod Millman) is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "regex.html",
    "href": "regex.html",
    "title": "Regular expressions",
    "section": "",
    "text": "Regular expressions (regex) are a domain-specific language for finding patterns and are one of the key functionalities in scripting languages such as Python, as well as the UNIX utilities sed, awk, and grep. We’ll just cover the basic use of regular expressions in bash, but once you know that, it would be easy to use them elsewhere (Python, R, etc.). At the level we’ll consider them, the syntax is quite similar.",
    "crumbs": [
      "Regular Expressions"
    ]
  },
  {
    "objectID": "regex.html#overview-and-core-syntax",
    "href": "regex.html#overview-and-core-syntax",
    "title": "Regular expressions",
    "section": "1 Overview and core syntax",
    "text": "1 Overview and core syntax\nThe basic idea of regular expressions is that they allow us to find matches of strings or patterns in strings, as well as do substitution. Regular expressions are good for tasks such as:\n\nextracting pieces of text - for example finding all the phone numbers in a document;\ncreating variables from information found in text;\ncleaning and transforming text into a uniform format;\nmining text by treating documents as data; and\nscraping the web for data.\n\nRegular expressions are constructed from three things:\n\nLiteral characters are matched only by the characters themselves,\nCharacter classes are matched by any single member in the class, and\nModifiers operate on either of the above or combinations of them.\n\nNote that the syntax is very concise, so it’s helpful to break down individual regular expressions into the component parts to understand them. Since regex are their own language, it’s a good idea to build up a regex in pieces as a way of avoiding errors just as we would with any computer code. You’ll also want to test your regex on examples, for which this online testing tool is helpful.\nIt is also helpful to search for common regex online before trying to craft your own. For instance, if you wanted to use a regex that matches valid email addresses, you would need to match anything that complies with the RFC 822 grammar. If you look over that document, you will quickly realize that implementing a correct regular expression to validate email addresses is extremely complex. So if you are writing a website that validates email addresses, it is best to look for a bug-vetted implementation rather than creating your own.\nThe special characters (meta-characters) used for defining regular expressions are:\n* . ^ $ + ? ( ) [ ] { } | \\\nTo use these characters literally as characters, we have to ‘escape’ them. In bash, you escape these characters by placing a single backslash before the character you want to escape. In R, we have to use two backslashes instead of a single backslash because R uses a single backslash to symbolize certain control characters, such as \\n for newline.\nTo learn more about regular expressions, you can type:\n$ man 7 regex",
    "crumbs": [
      "Regular Expressions"
    ]
  },
  {
    "objectID": "regex.html#character-sets-and-character-classes",
    "href": "regex.html#character-sets-and-character-classes",
    "title": "Regular expressions",
    "section": "2 Character sets and character classes",
    "text": "2 Character sets and character classes\nWe can use character sets to match any of the characters in a set.\n\n\n\n\nOperators\n\n\nDescription\n\n\n\n\n\n\n[abc]\n\n\nMatch any single character from from the listed characters\n\n\n\n\n[a-z]\n\n\nMatch any single character from the range of characters\n\n\n\n\n[^abc]\n\n\nMatch any single character not among listed characters\n\n\n\n\n[^a-z]\n\n\nMatch any single character not among listed range of characters\n\n\n\n\n.\n\n\nMatch any single character except a newline\n\n\n\n\n&lt;/code&gt;\n\n\nTurn off (escape) the special meaning of a metacharacter\n\n\n\n\nIf we want to search for any one of a set of characters, we use a character set, such as [13579] or [abcd] or [0-9] (where the dash indicates a sequence) or [0-9a-z]. To indicate any character not in a set, we place a ^ just inside the first bracket: [^abcd].\nHere’s an example of using regex with grep to find all lines in test.txt that contain at least one numeric digit.\n$ grep -E [0-9] test.txt     \nor with the -o flag to find and return only the actual digits\n$ grep -E -o [0-9] test.txt     \nThere are a bunch of named character classes so that we don’t have write out common sets of characters. The syntax is [:CLASS:] where CLASS is one of the following values:\n\"alnum\", \"alpha\", \"ascii\", \"blank\", \"cntrl\", \"digit\", \"graph\",\n\"lower\", \"print\", \"punct\", \"space\", \"upper\", \"word\" or \"xdigit\".\nSo to find any line that contains a punctuation symbol:\n$ grep -E [[:punct:]] test.txt\nNote that to make a character set with a character class you need two square brackets, e.g., with the digit class: [[:digit:]]. Or we can make a combined character set such as [[:alnum:]_] (to find any alphabetic or numeric characters or an underscore). Or here, any line with a digit, a period, or a comma.\n$ grep -E [[:digit:].,] test.txt\nInterestingly, we don’t need to escape the period or comma inside the character set, despite both of them being meta-characters.",
    "crumbs": [
      "Regular Expressions"
    ]
  },
  {
    "objectID": "regex.html#location-specific-matches",
    "href": "regex.html#location-specific-matches",
    "title": "Regular expressions",
    "section": "3 Location-specific matches",
    "text": "3 Location-specific matches\nWe can use position anchors to make location-specific matches.\n\n\n\n\nOperators\n\n\nDescription\n\n\n\n\n\n\n^\n\n\nMatch the beginning of a line.\n\n\n\n\n$\n\n\nMatch the end of a line.\n\n\n\n\nTo find a pattern at the beginning of the string, we use ^ (note this was also used for negation, but in that case occurs only inside square brackets) and to find it at the end we use $.\nHere we’ll search for lines that start with a digit and for lines that end with a digit.\n$ grep -E ^[0-9] test.txt\n$ grep -E [0-9]$ test.txt",
    "crumbs": [
      "Regular Expressions"
    ]
  },
  {
    "objectID": "regex.html#repetitions-grouping-and-references",
    "href": "regex.html#repetitions-grouping-and-references",
    "title": "Regular expressions",
    "section": "4 Repetitions, Grouping, and References",
    "text": "4 Repetitions, Grouping, and References\nNow suppose I wanted to be able to detect phone numbers, email addresses, etc. I often need to be able to deal with repetitions of characters or character sets.\nModifiers\n\n\n\n\nOperators\n\n\nDescription\n\n\n\n\n\n\n*\n\n\nMatch zero or more instances of the preceding character or regex.\n\n\n\n\n?\n\n\nMatch zero or one instance of the preceding character or regex.\n\n\n\n\n+\n\n\nMatch one or more instances of the preceding character or regex.\n\n\n\n\n{n,m}\n\n\nMatch a range of occurrences (at least n, no more than m) of preceding character of regex.\n\n\n\n\n|\n\n\nMatch the character or expression to the left or right of the vertical bar.\n\n\n\n\nHere are some examples of repetitions:\n\n[[:digit:]]* : any number of digits (zero or more)\n[[:digit:]]+ : at least one digit\n[[:digit:]]? : zero or one digits\n[[:digit:]]{1,3} : at least one and no more than three digits\n[[:digit:]]{2,} : two or more digits\n\nAnother example is that \\[.*\\] is the pattern of closed square brackets with any number of characters (.*) inside:\n﻿$ grep -E \"\\[.*\\]\" test.txt\nNote that the quotations ensured that the backslashes are passed into grep and not simply interpreted by the shell, while the \\ is needed so that [ and ] are treated as simple characters since they are meta-characters in the regex syntax.\nAs shown above, we can use | to mean “or”. For example, to match one or more occurrences of “http” or “ftp”:\n$ grep -E -o \"(http|ftp)\" test.txt\nParentheses are also used with a pipe (|) when working with multi-character sequences, such as (http|ftp). Also, here we need double quotes or the shell tries to interpret the ( as part of the regular expression and not shell syntax.\nNext let’s see the use of repitition to look for more complicated multi-character patterns. For example, if you wanted to match phone numbers whether they start with 1- or not you could use the following:\n(1-)?[[:digit:]]{3}-[[:digit:]]{3}-[[:digit:]]{4}\nThe first part of the pattern (1-)? matches 0 or 1 occurrences of 1-. Then the pattern [[:digit:]]{3} matches any 3 digits. Similarly, the pattern [[:digit:]]{4} matches any 4 digits. So the whole pattern matches any three digits followed by -, then another three digits, and then followed by four digits when it is preceded by 0 or 1 occurrences of 1-.\nNow let’s consider a file named file2.txt with the following content:\n    Here is my number: 919-543-3300.\n    hi John, good to meet you\n    They bought 731 bananas\n    Please call 1.919.554.3800\n    I think he said it was 337.4355\nLet’s use a regular expression pattern to print all lines containing phone numbers:\n$ grep '(1-)?[[:digit:]]{3}-[[:digit:]]{4}' file2.txt\nYou will notice that this doesn’t match any lines. The reason is that the group syntax (1-) and the {} notation are not part of the extended syntax. To have grep use the extended syntax, you can either use the -E option (as we’ve been doing above):\n$ grep -E '(1-)?[[:digit:]]{3}-[[:digit:]]{4}' file2.txt\nHere is my number: 919-543-3300.\nor use the egrep command:\n$ egrep  '(1-)?[[:digit:]]{3}-[[:digit:]]{4}' file2.txt\nHere is my number: 919-543-3300.\nIf we want to match regardless of whether the phone number is separated by a minus - or a period ., we could use the pattern [-.]:\n$ egrep  '(1[-.])?[[:digit:]]{3}[-.][[:digit:]]{4}' file2.txt\nHere is my number: 919-543-3300.\nPlease call 1.919.554.3800\nI think he said it was 337.4355\n\n\n\n\n\n\nExercise\n\n\n\nExplain what the following regular expression matches:\n$ grep '^[^T]*is.*$' file1.txt",
    "crumbs": [
      "Regular Expressions"
    ]
  },
  {
    "objectID": "regex.html#greedy-matching",
    "href": "regex.html#greedy-matching",
    "title": "Regular expressions",
    "section": "5 Greedy matching",
    "text": "5 Greedy matching\nRegular expression pattern matching is greedy—by default, the longest matching string is chosen.\nSuppose we have the following file:\n$ cat file1.txt\nDo an internship &lt;b&gt; in place &lt;/b&gt; of &lt;b&gt; one &lt;/b&gt; course.\nIf we want to match the html tags (e.g., &lt;b&gt; and &lt;/b&gt;, we might be tempted to use the pattern &lt;.*&gt;. Using the -o option to grep, we can have grep print out just the part of the text that the pattern matches:\n$ grep -o \"&lt;.*&gt;\" file1.txt\n&lt;b&gt; in place &lt;/b&gt; of &lt;b&gt; one &lt;/b&gt;\nTo get a non-greedy match, you can use the modifier ? after the quantifier. However, this requires that we use the Perl syntax. In order for grep to use the Perl syntax, we need to use the -P option:\n$ grep -P -o \"&lt;.*?&gt;\" file1.txt\n&lt;b&gt;\n&lt;/b&gt;\n&lt;b&gt;\n&lt;/b&gt;\nHowever, one can often avoid greedy matching by being more clever.\n\n\n\n\n\n\nChallenge\n\n\n\nHow could we change our regexp to avoid the greedy matching without using the ? modifier? Hint: Is there some character set that we don’t want to be inside the angle brackets?\n\n\n\n\n\n\n\n\nglobs vs. regex\n\n\n\nBe sure you understand the difference between filename globbing and regular expressions. Filename globbing only works for filenames, while regular expressions are used to match patterns in text more generally. While they both use the same set of symbols, they mean different things (e.g., * matches 0 or more characters when globbing but matches 0 or more repetitions of the character that precedes it when used in a regular expression).",
    "crumbs": [
      "Regular Expressions"
    ]
  }
]